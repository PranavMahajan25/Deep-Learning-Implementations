{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_pytorch(fast.ai).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/PranavMahajan25/Deep-Learning-Implementations/blob/master/RNN_pytorch(fast_ai).ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "wRa8nZyuH2mc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "!pip3 install fastai\n",
        "!pip3 install spacy && python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHEEnwIVqJu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ov3O_syNumyh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.io import *\n",
        "from fastai.conv_learner import *\n",
        "\n",
        "from fastai.column_data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PelV1wXNP51r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb5efe7f-e517-42c6-e9a1-e04fc19f1bca"
      },
      "cell_type": "code",
      "source": [
        "PATH='data/nietzsche/'\n",
        "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
        "text = open(f'{PATH}nietzsche.txt').read()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y_MUnlhH2ET3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c9048dba-2361-4516-e7eb-b7d39183c41a"
      },
      "cell_type": "code",
      "source": [
        "text[:500]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been unskilled and unseemly methods for\\nwinning a woman? Certainly she has never allowed herself to be won; and\\nat present every kind of dogma stands with sad and discouraged mien--IF,\\nindeed, it s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "-LtwKDlG98-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0463685b-bfc1-41ba-cd96-2c5497761192"
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)+1\n",
        "chars.insert(0, \"\\0\")\n",
        "print('total chars:', vocab_size)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NisIAqvU-fxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6e863bf6-1fd6-497f-d518-8426bf2c9272"
      },
      "cell_type": "code",
      "source": [
        "print(chars[0:-6])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\x00', '\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NcOva1ij-kym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bceef65-a48d-4c61-cb1d-00599d6b1730"
      },
      "cell_type": "code",
      "source": [
        "char_indices = {c: i for i, c in enumerate(chars)}\n",
        "idx = [char_indices[c] for c in text]\n",
        "idx[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "JhrVbVXE_Zmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "adcdfed6-81d3-4d0a-aaa8-a02265877471"
      },
      "cell_type": "code",
      "source": [
        "indices_char = {i: c for i, c in enumerate(chars)}\n",
        "charx = [indices_char[i] for i in [40,42,29,30,25,27,29,1,1,1]]\n",
        "charx[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['P', 'R', 'E', 'F', 'A', 'C', 'E', '\\n', '\\n', '\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "o80lTJABANuv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#3 char model"
      ]
    },
    {
      "metadata": {
        "id": "RFLC7wM-_9Xk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=3\n",
        "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
        "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
        "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
        "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UikHMmbCAdFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = np.stack(c1_dat)\n",
        "x2 = np.stack(c2_dat)\n",
        "x3 = np.stack(c3_dat)\n",
        "y = np.stack(c4_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGKos-w_Alkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6a50ed3-8004-41b1-f1ce-fb12761baa4c"
      },
      "cell_type": "code",
      "source": [
        "x1[:4], x2[:4], x3[:4]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "TEk4-8IKArNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af484788-6ca3-464f-b776-73c716cb7a22"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y[:4]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 29,  1, 40])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "h5ZELm_SAvrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8b6e6ed-7ee3-4a0d-d9c2-216ace1a95b4"
      },
      "cell_type": "code",
      "source": [
        "x1.shape,y.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200297,), (200297,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "UFdE0_p7A62x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden = 256\n",
        "n_fac=42 #embeddings size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vF_UXMn2BEJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Char3Model(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "\n",
        "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "\n",
        "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        \n",
        "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, c1, c2, c3):\n",
        "        in1 = F.relu(self.l_in(self.e(c1)))\n",
        "        in2 = F.relu(self.l_in(self.e(c2)))\n",
        "        in3 = F.relu(self.l_in(self.e(c3)))\n",
        "        \n",
        "        h = V(torch.zeros(in1.size()).cuda())\n",
        "        h = F.tanh(self.l_hidden(h+in1))\n",
        "        h = F.tanh(self.l_hidden(h+in2))\n",
        "        h = F.tanh(self.l_hidden(h+in3))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJAxZk-ZBrVt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)\n",
        "\n",
        "m =  Char3Model(vocab_size, n_fac).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EN-cZCpxB7mk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "edhyIWcpCZ6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "daef0b9d-d364-466a-d0b2-a25092094b15"
      },
      "cell_type": "code",
      "source": [
        "md,\n",
        "md.trn_dl,\n",
        "it,\n",
        "xs,\n",
        "yt,\n",
        "t"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "-4.6761 -4.4326 -4.2251  ...  -4.6642 -4.8194 -4.4240\n",
              "-4.5821 -4.2972 -4.3980  ...  -4.6519 -4.6038 -4.4318\n",
              "-4.6093 -4.2848 -4.3186  ...  -4.3018 -4.4857 -4.6288\n",
              "          ...             ⋱             ...          \n",
              "-4.2546 -4.5138 -4.4584  ...  -4.6267 -4.4684 -4.4786\n",
              "-4.5246 -4.5423 -4.5485  ...  -4.8612 -4.6206 -4.3814\n",
              "-4.5089 -4.4401 -4.4121  ...  -4.7843 -4.7301 -4.2392\n",
              "[torch.cuda.FloatTensor of size 512x85 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "JX5dijjdCb0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "86cf8644-855c-424b-87a3-98b77c2d8fc1"
      },
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(m.parameters(), 1e-2)\n",
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2af61b7a45f44599943224e808413723",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.116363   1.166479  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.16648])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "NSlIQT-qDD16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4d2e1490-82e5-4a71-c4c9-0fe5ec318d1b"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)\n",
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21445bd1e7114308afba39e0b536da0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.85875    0.879778  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.87978])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "3DsaWBZdDIgm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jb43yXx8DbYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10e82c22-4587-442b-9e18-bdf37bf28b9f"
      },
      "cell_type": "code",
      "source": [
        "get_next('tru')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "UdSx6SqLEfMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#RNN using concatenation"
      ]
    },
    {
      "metadata": {
        "id": "F5MYTVNnEeV3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs =8 #size of unrolled rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8JvbLTIDgyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZgeTI6-ExxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGPcQvTfE2uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3149ad4-1d0e-4a62-c19a-3668d1a0358a"
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat, axis=0)\n",
        "xs.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600885, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "8vHv-6DYFBS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c_out_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "He85hZquFJMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "c840091a-25ad-431b-cc1f-ee4ec7f157b3"
      },
      "cell_type": "code",
      "source": [
        "xs[:20,:cs]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
              "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
              "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
              "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
              "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
              "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
              "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
              "       [ 1,  1,  1, 43, 45, 40, 40, 39],\n",
              "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
              "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
              "       [43, 45, 40, 40, 39, 43, 33, 38],\n",
              "       [45, 40, 40, 39, 43, 33, 38, 31],\n",
              "       [40, 40, 39, 43, 33, 38, 31,  2],\n",
              "       [40, 39, 43, 33, 38, 31,  2, 73],\n",
              "       [39, 43, 33, 38, 31,  2, 73, 61],\n",
              "       [43, 33, 38, 31,  2, 73, 61, 54],\n",
              "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
              "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
              "       [31,  2, 73, 61, 54, 73,  2, 44],\n",
              "       [ 2, 73, 61, 54, 73,  2, 44, 71]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "OTMX3FBKFNNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16eaa129-b617-4207-d25d-40bec7b60f0a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y[:20]\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, 43, 45, 40, 40, 39, 43, 33, 38, 31,  2, 73, 61, 54, 73,  2, 44, 71, 74])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "k2cjKO3UFYcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(idx)-cs-1)\n",
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K-HV_fHcFiE5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopConcatModel(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = torch.cat((h, self.e(c)), 1)\n",
        "            inp = F.relu(self.l_in(inp))\n",
        "            h = F.tanh(self.l_hidden(inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8xSCdb2OFb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a2829ecf-5be2-483f-cb9d-533a0b445f8a"
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)\n",
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f52f801dcb03409cb46cb7c0eba86e97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.813198   1.796775  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.79678])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "o8X8DQfaOLrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "6af26555-332f-4284-d58a-05f9eeeeedd8"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d40c078c880e48dd8b9e0e40417d476b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.716738   1.721608  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.72161])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "QWwHlG7UO2DH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6253b414-245d-411f-8d07-4d6e54a97ae0"
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "paKeBoNKJl1k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#RNN using builtin function by pytorch\n",
        "compare with CharLoopConcateModel"
      ]
    },
    {
      "metadata": {
        "id": "1velRPb8PDwz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs)) #let's find out what this stack is ? also let's checkout weight matrices in rnn\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        \n",
        "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcxeZVfh3aA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "9c57094d-d976-4b0a-b137-c9c2ff4d2fbe"
      },
      "cell_type": "code",
      "source": [
        "m = CharRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)\n",
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "306e4f008b80483c8128d3bac4b027c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.867699   1.846299  \n",
            " 22%|██▏       | 211/939 [00:06<00:21, 34.43it/s, loss=1.8] "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.671898   1.672194  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.595611   1.596666  \n",
            "    3      1.533915   1.55066   \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.55066])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "ujifBivB5aWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b96ea03b-6dc2-4f84-d93f-93fcf2fc0683"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "\n",
        "fit(m, md, 2, opt, F.nll_loss)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "460e5ae8104e4d1aa4383ab30f661d27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.472107   1.512657  \n",
            " 22%|██▏       | 211/939 [00:06<00:20, 34.91it/s, loss=1.45]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.466541   1.507175  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.50718])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "G0lUWUkE5q8l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res\n",
        "get_next_n('strong love',100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VKojlSv6GUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22c117de-ebe0-49d8-d3c5-ccd257fe0d88"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('have been',100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have been strong the same to the same to the same to the same to the same to the same to the same to the sam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "scd4wToU6fO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed27597a-f070-4f76-ea1e-03acde6ef5ff"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('much like',100)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'much like the same to the same to the same to the same to the same to the same to the same to the same to the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "p1O6-gpd6i3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8849330-8ae0-4139-f585-8c3fe714493f"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('I miss my days',100)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I miss my days and the same to the same to the same to the same to the same to the same to the same to the same to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "Ri_j0qR96tVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75bf9bd2-e835-4445-9029-94b3b1393d12"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('which they have',100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'which they have a strong the same to the same to the same to the same to the same to the same to the same to the sa'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "jyh1ov7W64Bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "600203fd-5de4-4e8a-9251-ef6cf63b7cc9"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('understanding women',100)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'understanding women and the same to the same to the same to the same to the same to the same to the same to the same to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "dpflCHs47D_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]\n",
        "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kyxid6Ig8chR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "799c4545-2ad6-424f-c8df-ab4bd01216a0"
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat)\n",
        "ys = np.stack(c_out_dat)\n",
        "xs.shape,ys.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((75111, 8), (75111, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "XysKeOmo8dam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "9a9c1deb-4744-4d44-f308-26d68fd9da78"
      },
      "cell_type": "code",
      "source": [
        "xs[:20,:cs]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
              "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
              "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
              "       [ 2, 44, 71, 74, 73, 61,  2, 62],\n",
              "       [72,  2, 54,  2, 76, 68, 66, 54],\n",
              "       [67,  9,  9, 76, 61, 54, 73,  2],\n",
              "       [73, 61, 58, 67, 24,  2, 33, 72],\n",
              "       [ 2, 73, 61, 58, 71, 58,  2, 67],\n",
              "       [68, 73,  2, 60, 71, 68, 74, 67],\n",
              "       [57,  1, 59, 68, 71,  2, 72, 74],\n",
              "       [72, 69, 58, 56, 73, 62, 67, 60],\n",
              "       [ 2, 73, 61, 54, 73,  2, 54, 65],\n",
              "       [65,  2, 69, 61, 62, 65, 68, 72],\n",
              "       [68, 69, 61, 58, 71, 72,  8,  2],\n",
              "       [62, 67,  2, 72, 68,  2, 59, 54],\n",
              "       [71,  2, 54, 72,  2, 73, 61, 58],\n",
              "       [78,  2, 61, 54, 75, 58,  2, 55],\n",
              "       [58, 58, 67,  1, 57, 68, 60, 66],\n",
              "       [54, 73, 62, 72, 73, 72,  8,  2],\n",
              "       [61, 54, 75, 58,  2, 59, 54, 62]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "9v2P8pvH8ppm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "efd7095a-abde-40cc-9709-81c4f620b16d"
      },
      "cell_type": "code",
      "source": [
        "ys[:20,:cs]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[42, 29, 30, 25, 27, 29,  1,  1],\n",
              "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
              "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
              "       [44, 71, 74, 73, 61,  2, 62, 72],\n",
              "       [ 2, 54,  2, 76, 68, 66, 54, 67],\n",
              "       [ 9,  9, 76, 61, 54, 73,  2, 73],\n",
              "       [61, 58, 67, 24,  2, 33, 72,  2],\n",
              "       [73, 61, 58, 71, 58,  2, 67, 68],\n",
              "       [73,  2, 60, 71, 68, 74, 67, 57],\n",
              "       [ 1, 59, 68, 71,  2, 72, 74, 72],\n",
              "       [69, 58, 56, 73, 62, 67, 60,  2],\n",
              "       [73, 61, 54, 73,  2, 54, 65, 65],\n",
              "       [ 2, 69, 61, 62, 65, 68, 72, 68],\n",
              "       [69, 61, 58, 71, 72,  8,  2, 62],\n",
              "       [67,  2, 72, 68,  2, 59, 54, 71],\n",
              "       [ 2, 54, 72,  2, 73, 61, 58, 78],\n",
              "       [ 2, 61, 54, 75, 58,  2, 55, 58],\n",
              "       [58, 67,  1, 57, 68, 60, 66, 54],\n",
              "       [73, 62, 72, 73, 72,  8,  2, 61],\n",
              "       [54, 75, 58,  2, 59, 54, 62, 65]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "zbaIMuxm8uQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(xs)-cs-1)\n",
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)\n",
        "class CharSeqRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1)\n",
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)\n",
        "it = iter(md.trn_dl)\n",
        "*xst,yt = next(it)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7BeMtYm9Qnm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nll_loss_seq(inp, targ):\n",
        "    sl,bs,nh = inp.size()\n",
        "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
        "    return F.nll_loss(inp.view(-1,nh), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ji2HVGxo9vIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "dfa9ae3d-defb-4286-82be-c4a2413a5e91"
      },
      "cell_type": "code",
      "source": [
        "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))  ##Hinton's 2015 paper"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    1     0     0  ...      0     0     0\n",
              "    0     1     0  ...      0     0     0\n",
              "    0     0     1  ...      0     0     0\n",
              "       ...          ⋱          ...       \n",
              "    0     0     0  ...      1     0     0\n",
              "    0     0     0  ...      0     1     0\n",
              "    0     0     0  ...      0     0     1\n",
              "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "MG9183l19Wj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "3010276f-8178-467a-da78-046a994d2b82"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ff10e37c5ca47beabaa3ab99f80778b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.367242   2.308005  \n",
            "    1      2.269234   2.238829  \n",
            "    2      2.213178   2.19687   \n",
            "    3      2.179532   2.166616  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.16662])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "B8tgEsuC9YpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "134cf6db-fd9f-4505-9dfb-f5b571b991a7"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "fit(m, md, 1, opt, nll_loss_seq)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "396ba10eeb64487ebb485a86dd3ef8fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.149212   2.143031  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.14303])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "qEJPZSwp-WkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Stateful model"
      ]
    },
    {
      "metadata": {
        "id": "9GBIpGX6bQqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cd3465b-f0a0-4a59-93a5-1e572e212e42"
      },
      "cell_type": "code",
      "source": [
        "!cat data/nietzsche/nietzsche.txt | wc -l"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9934\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JcPs7hZGb_8g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data/nietzsche/trn\n",
        "!mkdir data/nietzsche/val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8oivyn6Pbnfe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!head -n 7000 data/nietzsche/nietzsche.txt | tee data/nietzsche/trn/trn.txt\n",
        "!tail -n 2934 data/nietzsche/nietzsche.txt | tee data/nietzsche/val/val.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPbOJvDFcRde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8de6f72-3bea-4f8f-9bde-c56f4ddb48fb"
      },
      "cell_type": "code",
      "source": [
        "!cat data/nietzsche/trn/trn.txt | wc -l"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1OA2DWgbd-Wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f6b7da9-2fee-4ae0-ea57-242303c22f61"
      },
      "cell_type": "code",
      "source": [
        "!cat data/nietzsche/val/val.txt | wc -l"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2933\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bMieuERy-UxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2731c4ec-2dfc-499e-9c65-a6dc7e76e6ce"
      },
      "cell_type": "code",
      "source": [
        "from torchtext import vocab, data\n",
        "\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *\n",
        "\n",
        "PATH='data/nietzsche/'\n",
        "\n",
        "TRN_PATH = 'trn/'\n",
        "VAL_PATH = 'val/'\n",
        "TRN = f'{PATH}{TRN_PATH}'\n",
        "VAL = f'{PATH}{VAL_PATH}'\n",
        "\n",
        "# Note: The student needs to practice her shell skills and prepare her own dataset before proceeding:\n",
        "# - trn/trn.txt (first 80% of nietzsche.txt)\n",
        "# - val/val.txt (last 20% of nietzsche.txt)\n",
        "\n",
        "%ls {PATH}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt  \u001b[0m\u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fs6wgOhJYkFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b809852-c200-4a86-c7c9-183382cbba14"
      },
      "cell_type": "code",
      "source": [
        "%ls {PATH}trn"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trn.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8-i4V6ELaC5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f63ea0d-5050-47e5-cd4b-481bc48c0ed1"
      },
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True, tokenize=list)\n",
        "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
        "\n",
        "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
        "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
        "\n",
        "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(837, 54, 1, 429135)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "tkYGtsGmekCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source\n",
        "\n",
        "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZIHgOexqeH6Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn2(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp = []\n",
        "        o = self.h\n",
        "        for c in cs: \n",
        "            o = self.rnn(self.e(c), o)\n",
        "            outp.append(o)\n",
        "        outp = self.l_out(torch.stack(outp))\n",
        "        self.h = repackage_var(o)\n",
        "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83UNUPE_eqOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTPg5-AJevmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "38b6dd85-4c33-4458-d368-df3bda85814e"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82ef3c8191214767a623feb75a05ed6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.896546   1.913566  \n",
            " 36%|███▌      | 298/837 [00:05<00:10, 51.37it/s, loss=1.82]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.706597   1.742194  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.616072   1.669026  \n",
            "    3      1.560965   1.627798  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.6278])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "20Fb9fOFe_3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#GRU and LSTM cells instead of RNN cells give better performance"
      ]
    },
    {
      "metadata": {
        "id": "F1JPj_tje1iT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))\n",
        "      \n",
        "# From the pytorch source code - for reference\n",
        "\n",
        "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    gi = F.linear(input, w_ih, b_ih)\n",
        "    gh = F.linear(hidden, w_hh, b_hh)\n",
        "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
        "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
        "\n",
        "    resetgate = F.sigmoid(i_r + h_r)\n",
        "    inputgate = F.sigmoid(i_i + h_i)\n",
        "    newgate = F.tanh(i_n + resetgate * h_n)\n",
        "    return newgate + inputgate * (hidden - newgate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWMw_Yt1fO3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "3915c4eb-6b8e-4373-f172-634f79e1d833"
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
        "\n",
        "opt = optim.Adam(m.parameters(), 1e-3)\n",
        "\n",
        "fit(m, md, 6, opt, F.nll_loss)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9dfa1033b3e442b96f60d1d7b0f28ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.770318   1.77696   \n",
            " 39%|███▉      | 329/837 [00:04<00:06, 80.94it/s, loss=1.67]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.578865   1.62333   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.486993   1.564848  \n",
            "    3      1.429499   1.526052  \n",
            " 14%|█▍        | 118/837 [00:01<00:09, 78.28it/s, loss=1.43]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      1.383741   1.508247  \n",
            "    5      1.353114   1.494747  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.49475])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "6HxAwf12fXNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "0ebb2b17-ed52-45ad-937c-1dfd8474c28b"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "\n",
        "fit(m, md, 3, opt, F.nll_loss)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9de71b3ff54a4d56831cd18c070fb96b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.258307   1.462969  \n",
            " 39%|███▉      | 330/837 [00:04<00:06, 79.77it/s, loss=1.31]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.269495   1.459366  \n",
            "    2      1.26746    1.456618  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.45662])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "DdO_SI-5gl2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "New get_next() and get_next_n() for TEXT.vocab"
      ]
    },
    {
      "metadata": {
        "id": "fvQ3w4fyfboV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = TEXT.numericalize(inp)\n",
        "    p = m(VV(idxs.transpose(0,1)))\n",
        "    r = torch.multinomial(p[-1].exp(), 1)\n",
        "    return TEXT.vocab.itos[to_np(r)[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzeCNolggF2W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GAPwv3UXgz9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "91671c92-bc29-48bd-ebc4-7317e7fb059f"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('have been', 400)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have been:\" and like in a perhaps their more edisting--i headts, delicable; and ofy sympaths, of the french a soul, how man is their daven at a kind\" all their extraordinarys?106. after visively to doing consequents,a cluminty and have requires good man as fear is adox, seld missepularity in the world of every his age along with the ear tastes ofmaniter \"modern an actificatism, owingstrould madator! and in'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "f-JrCzYXg6jJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3a58b1c1-db9a-4db6-918c-398c57d50114"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('much like',400)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"much like probowing more will ambition.         a. a unemotively;it were commands will out for the very no longer cational exaking wellcaustranted thanthat is thusing--aswowlerngs, it was really this point of the insurely. them with sighed on earthandinfour into tastes putting--or whom experience of   day laughto: he with such merely knowadays, go one's ofentermerrow-previrtue, who to taking owing to helle\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "mgREKeQPhcLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fcfb17dd-e376-4c67-bc82-41e9e79ad1be"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('I miss my days',400)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I miss my days in more magnish what is that among occasion of austaptics with sative scientifictest then someon specism has also one a actuals which he belief! they hard, bound to recognizul of the metaphysical taught in everythingnere, they are honemelands, thepossibility, that it was free spirit in the doubity difficult\" is actificated induce forms of arrum, and old into allow to comporiousness?).--but we kno'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-sKxPzVh03A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f1f6acc6-7671-4c07-9eb3-5aec0b45503b"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('understanding women',400)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'understanding women took find all especially richard except occurredincertance.\" the speek tooly, is not he worth in its estimatest is requirement nay! but \"age (as in some laitsynsiouss and requirestant,than also about him thinking isteeps or is milled into bot up toagnerating which ordinary more costors of distrust;ay the belier, and is crebeianity, fact we are the amble, and love of the maturity; one dis vicionar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "Zpi4D2OqixgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import sgdr\n",
        "\n",
        "n_hidden=512\n",
        "\n",
        "class CharSeqStatefulLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
        "        super().__init__()\n",
        "        self.vocab_size,self.nl = vocab_size,nl\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs):\n",
        "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
        "                  V(torch.zeros(self.nl, bs, n_hidden)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtKVxfAQjEdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "dd951cf3-6a84-4f32-d247-de6323e3ee43"
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
        "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)\n",
        "os.makedirs(f'{PATH}models', exist_ok=True)\n",
        "fit(m, md, 2, lo.opt, F.nll_loss)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1391fb6d66a948daa85926a0f4fed72e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.928408   1.852095  \n",
            " 34%|███▍      | 288/837 [00:06<00:11, 46.80it/s, loss=1.84]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.725508   1.671039  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.67104])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "9VlyeCUPjPXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "cac1ea01-ff8b-46f6-c244-c77d46709b6f"
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c175c65268744a39b1bc386dfee8645",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.529105   1.522802  \n",
            " 33%|███▎      | 278/837 [00:06<00:12, 46.17it/s, loss=1.65]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.575525   1.538003  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.427903   1.448071  \n",
            "    3      1.592513   1.581464  \n",
            "  8%|▊         | 64/837 [00:01<00:17, 44.97it/s, loss=1.59]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      1.491149   1.492414  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    5      1.398366   1.4258    \n",
            "    6      1.326546   1.393989  \n",
            " 11%|█         | 88/837 [00:01<00:16, 45.07it/s, loss=1.33]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    7      1.578389   1.546977  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    8      1.528047   1.523015  \n",
            "    9      1.479904   1.487113  \n",
            "  9%|▉         | 77/837 [00:01<00:16, 46.87it/s, loss=1.48]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    10     1.434823   1.46273   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    11     1.379255   1.415903  \n",
            "    12     1.335107   1.388118  \n",
            " 11%|█         | 89/837 [00:01<00:16, 46.14it/s, loss=1.34]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    13     1.281454   1.367052  \n",
            "    14     1.244399   1.356175  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.35618])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "PdnwJ-jLjfXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1235
        },
        "outputId": "3a901275-eb80-4680-ed8e-9a22d3679bd1"
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90a65b2d31f94710b4c7887b3fd23304",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.24186    1.353589  \n",
            " 34%|███▍      | 284/837 [00:06<00:11, 46.81it/s, loss=1.26]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.243437   1.352513  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.237277   1.351641  \n",
            "    3      1.24712    1.351353  \n",
            "  8%|▊         | 71/837 [00:01<00:17, 43.86it/s, loss=1.24]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      1.236016   1.349186  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    5      1.228558   1.347315  \n",
            "    6      1.224525   1.346814  \n",
            " 10%|▉         | 83/837 [00:01<00:16, 46.03it/s, loss=1.23]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    7      1.228065   1.348113  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    8      1.224632   1.346076  \n",
            "    9      1.221996   1.343949  \n",
            "  9%|▉         | 79/837 [00:01<00:16, 44.75it/s, loss=1.23]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    10     1.2122     1.342346  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    11     1.210542   1.341784  \n",
            "    12     1.20362    1.340894  \n",
            "  9%|▉         | 74/837 [00:01<00:16, 47.16it/s, loss=1.21]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    13     1.199315   1.340639  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    14     1.203851   1.340834  \n",
            "    15     1.204548   1.342453  \n",
            "  9%|▊         | 72/837 [00:01<00:15, 48.24it/s, loss=1.22]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    16     1.19942    1.341447  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    17     1.193645   1.341271  \n",
            "    18     1.193654   1.340717  \n",
            "  8%|▊         | 71/837 [00:01<00:17, 43.78it/s, loss=1.2]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    19     1.181273   1.340194  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    20     1.180488   1.340232  \n",
            "    21     1.175049   1.340909  \n",
            "  8%|▊         | 67/837 [00:01<00:17, 45.09it/s, loss=1.19]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    22     1.168731   1.340517  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    23     1.155431   1.340724  \n",
            "    24     1.16212    1.340466  \n",
            "  8%|▊         | 71/837 [00:01<00:16, 45.73it/s, loss=1.17]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    25     1.157973   1.341496  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    26     1.153812   1.341135  \n",
            "    27     1.148098   1.340845  \n",
            "  7%|▋         | 62/837 [00:01<00:17, 45.01it/s, loss=1.16]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    28     1.147169   1.341002  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    29     1.146775   1.341168  \n",
            "    30     1.148749   1.341432  \n",
            "  9%|▉         | 79/837 [00:01<00:16, 46.52it/s, loss=1.16]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    31     1.14709    1.341313  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    32     1.154382   1.342461  \n",
            "    33     1.149926   1.342664  \n",
            "  9%|▉         | 76/837 [00:01<00:16, 45.14it/s, loss=1.16]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    34     1.148443   1.343756  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    35     1.146194   1.344841  \n",
            "    36     1.135897   1.347349  \n",
            "  7%|▋         | 59/837 [00:01<00:17, 43.75it/s, loss=1.15]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    37     1.13267    1.348163  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    38     1.122121   1.349945  \n",
            "    39     1.115372   1.35079   \n",
            "  7%|▋         | 55/837 [00:01<00:16, 46.23it/s, loss=1.13]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    40     1.110733   1.35158   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    41     1.108059   1.35342   \n",
            "    42     1.106465   1.35494   \n",
            " 10%|▉         | 83/837 [00:01<00:16, 46.75it/s, loss=1.11]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    43     1.094476   1.356639  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    44     1.09381    1.358493  \n",
            "    45     1.081021   1.359306  \n",
            " 10%|█         | 86/837 [00:01<00:15, 47.85it/s, loss=1.09]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    46     1.077507   1.361001  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    47     1.084257   1.36307   \n",
            "    48     1.07713    1.364331  \n",
            " 10%|█         | 84/837 [00:01<00:15, 48.35it/s, loss=1.09]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    49     1.067957   1.364325  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    50     1.068184   1.3669    \n",
            "    51     1.064108   1.367267  \n",
            " 10%|▉         | 80/837 [00:01<00:16, 44.68it/s, loss=1.07]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    52     1.063409   1.368971  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    53     1.05448    1.369563  \n",
            "    54     1.045984   1.369652  \n",
            "  8%|▊         | 70/837 [00:01<00:16, 46.61it/s, loss=1.06]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    55     1.05042    1.370015  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    56     1.043335   1.37144   \n",
            "    57     1.046835   1.371699  \n",
            "  8%|▊         | 64/837 [00:01<00:16, 47.57it/s, loss=1.05]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    58     1.037568   1.372844  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    59     1.047029   1.373012  \n",
            "    60     1.049744   1.37371   \n",
            "  9%|▉         | 78/837 [00:01<00:17, 44.58it/s, loss=1.05]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    61     1.047995   1.373636  \n",
            "    62     1.042044   1.373721  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.37372])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "MLMrHoH5jiB4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}