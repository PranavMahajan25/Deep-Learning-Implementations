{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#action-->reward\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(42) #Done so that we start with the same random values. Makes debugging easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bandit_arms = [0.2,0.4,-0.3,-3] # Expected rewards for each bandit. \n",
    "num_arms = 4 #Total possible actions basically\n",
    "def getReward(bandit):\n",
    "    x = np.random.randn(1) # Gets a random number from the Gaussian distribution. Google Gaussian distribution if you haven't learned it yet.\n",
    "    if x > bandit:\n",
    "        return 2\n",
    "    else:\n",
    "        return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.ones(num_arms) # Initializing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWeight(action):\n",
    "    return weights[action] #built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_episodes = 1000\n",
    "total_rewards = np.zeros(num_arms)\n",
    "i = 0\n",
    "lr = 0.001 # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoreboard: [ 0.  0. -2.  0.]\n",
      "Scoreboard: [ -4. -10.   6.  30.]\n",
      "Scoreboard: [-10. -16.  20.  56.]\n",
      "Scoreboard: [-14. -26.   4.  86.]\n",
      "Scoreboard: [ -18.  -40.    2.  114.]\n",
      "Scoreboard: [ -18.  -44.    6.  134.]\n",
      "Scoreboard: [ -34.  -50.    4.  158.]\n",
      "Scoreboard: [ -48.  -48.   26.  168.]\n",
      "Scoreboard: [ -56.  -48.   40.  190.]\n",
      "Scoreboard: [ -48.  -62.   54.  218.]\n",
      "Scoreboard: [ -58.  -62.   58.  248.]\n",
      "Scoreboard: [ -68.  -70.   62.  266.]\n",
      "Scoreboard: [ -70.  -76.   64.  288.]\n",
      "Scoreboard: [ -74.  -84.   72.  308.]\n",
      "Scoreboard: [ -78.  -90.   80.  334.]\n",
      "Scoreboard: [ -86.  -94.   88.  370.]\n",
      "Scoreboard: [ -98.  -98.   86.  404.]\n",
      "Scoreboard: [ -84. -110.   82.  422.]\n",
      "Scoreboard: [ -80. -130.   90.  446.]\n",
      "Scoreboard: [ -90. -144.   88.  472.]\n"
     ]
    }
   ],
   "source": [
    "while i < total_episodes:\n",
    "    \n",
    "    action = np.random.randint(0,4) # Choosing a random action for training the model. 0 is included while 4 is not.\n",
    "    \n",
    "    output = getWeight(action) # Getting the weight corresponding to the chosen action.\n",
    "    \n",
    "    reward = getReward(bandit_arms[action]) # Getting the expected reward corresponding to the chosen action.\n",
    "    \n",
    "    loss = - (np.log(output)*reward) # Normal loss function .\n",
    "    \n",
    "    weights[action] = weights[action]+lr*reward*(1/output) # Updating the weights based on the loss calculated.\n",
    "    \n",
    "    total_rewards[action]+=reward # Keeping a track of which action is giving the most rewards.\n",
    "    \n",
    "    if i%50==0:\n",
    "        print(\"Scoreboard: \"+str(total_rewards))\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.899533    0.82772743  1.08486873  1.40736999]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(weights)+1 # Checking whether the model learned which action was best. 4 should be the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
